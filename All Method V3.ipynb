{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data & Removing Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Stock-Data-Optimization-2-Percent-06-29-2021.xlsm', sheet_name = 'Data')\n",
    "data = data.drop(data.columns[[33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48]], axis = 1) #drop the calculated column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the First Line as Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_header = data.iloc[0] #grab the first row for the header\n",
    "data = data[1:] #take the data less the header row\n",
    "data.columns = new_header #set the header row as the df header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input for Static Method - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_sma20 = -5\n",
    "upper_bound_sma20 = -2\n",
    "momentum = 0\n",
    "up_from_day = 0\n",
    "up_from_open = 9\n",
    "lower_bound_rsi = 64\n",
    "upper_bound_rsi = 70\n",
    "volume_ratio = 1.5\n",
    "market_cap = 2000\n",
    "\n",
    "min_event = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Method - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a00b382208a499ca6c066a4e41b3e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=512.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-5-090f58ac47f2>\", line 41, in method2\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 435, in __init__\n    mgr = init_dict(data, index, columns, dtype=dtype)\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 254, in init_dict\n    return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 69, in arrays_to_mgr\n    arrays = _homogenize(arrays, index, dtype)\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 323, in _homogenize\n    val, index, dtype=dtype, copy=False, raise_cast_failure=False\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\", line 465, in sanitize_array\n    subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype)\n  File \"C:\\Users\\91709\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\", line 1461, in construct_1d_arraylike_from_scalar\n    subarr = np.empty(length, dtype=dtype)\nTypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-090f58ac47f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mswitch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Multi Processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Concat all DataFrames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type"
     ]
    }
   ],
   "source": [
    "data['mrkt cap'] = data['mrkt cap'].fillna(0) #Fill Blank space in market cap with 0\n",
    "data['Volume Ratio'] = data['Volume Ratio'].fillna(0) #Fill Blank space in volume ratio with 0\n",
    "\n",
    "#Creating columns\n",
    "data.loc[(data['20SMA'] > data['50SMA'] ) , 'sma20 > sma50'] = 0\n",
    "data['sma20 > sma50'] = data['sma20 > sma50'].fillna(1)\n",
    "data.loc[(data['20SMA %'] < upper_bound_sma20) & (data['20SMA %'] > lower_bound_sma20) , 'sma20 bound check'] = 0\n",
    "data['sma20 bound check'] = data['sma20 bound check'].fillna(1)\n",
    "data.loc[(data['Mom'] > momentum) , 'momentum'] = 0\n",
    "data['momentum'] = data['momentum'].fillna(1)\n",
    "data.loc[(data['%Up'] > up_from_day) , '8% Daily'] = 0\n",
    "data['8% Daily'] = data['8% Daily'].fillna(1)\n",
    "data.loc[(data['% Open'] > up_from_open) , '2% UP'] = 0\n",
    "data['2% UP'] = data['2% UP'].fillna(1)\n",
    "data.loc[(data['14minRSI'] < upper_bound_rsi) & (data['14minRSI'] > lower_bound_rsi) , 'RSI (60-72)'] = 0\n",
    "data['RSI (60-72)'] = data['RSI (60-72)'].fillna(1)\n",
    "data.loc[(data['Volume Ratio'] < volume_ratio) , 'Volume Ration'] = 0\n",
    "data['Volume Ration'] = data['Volume Ration'].fillna(1)\n",
    "data.loc[(data['mrkt cap'] < market_cap) , 'market cap'] = 1\n",
    "data['market cap'] = data['market cap'].fillna(0)\n",
    "data.loc[(data['Macd'] == 'Pass') , 'MACD'] = 0\n",
    "data['MACD'] = data['MACD'].fillna(1)\n",
    "\n",
    "#Creating all the On, Off scenarios\n",
    "switch = list(itertools.product(['ON', 'OFF'], ['ON', 'OFF'], ['ON', 'OFF'], ['ON', 'OFF'], ['ON', 'OFF'], ['ON', 'OFF'],\\\n",
    "                       ['ON', 'OFF'], ['ON', 'OFF'], ['ON', 'OFF']))\n",
    "\n",
    "df = data[['sma20 > sma50','sma20 bound check', 'momentum', '8% Daily', '2% UP', 'RSI (60-72)', 'Volume Ration', \\\n",
    "           'market cap', 'MACD', 'win', 'upwin', 'Loss', 'update loss' ]] #Selecting relevant columns\n",
    "\n",
    "#Iteration\n",
    "def method2(j):\n",
    "    \n",
    "    #Creating empty lists and Dataframe to be used in iterations\n",
    "    indices = []\n",
    "    col_name = []\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    lis = list(j) #Selecting one scenario at a time for iteration\n",
    "    new_line = pd.DataFrame({'sma20 > sma50': lis[0], 'sma20percent': lis[1], 'momentum': lis[2], 'percentChange': lis[3],\\\n",
    "          'percentOverOpen': lis[4], 'RSI': lis[5], 'volumeRatio': lis[6], 'mktcap': lis[7], 'MACD': lis[8]}, index=[0])\n",
    "    #Creating new line with the On Off combination for that iteration\n",
    "    \n",
    "    #Determing the index of all the OFFs of the particular instance\n",
    "    for i in range(len(lis)):\n",
    "        if lis[i] == \"OFF\":\n",
    "            indices.append(i)\n",
    "    \n",
    "    #Getting the columns names of OFFs of the particular iteration\n",
    "    for c in indices:\n",
    "        col = df.columns[c]\n",
    "        col_name.append(col)\n",
    "    try:\n",
    "        temp = df.drop(columns = col_name) #Drop all the OFF columns\n",
    "        df_win = temp[temp['win'] == 1] #Filter the dataset where win is 1\n",
    "        df_win[\"count\"] = df_win.sum(axis=1) #Create a new column and sum each row\n",
    "        win_count = df_win[\"count\"].value_counts() #Get the frequency of result at store in the series\n",
    "        win_filter = win_count.to_frame() #Convert the series to Dataframe\n",
    "        win_filter = win_filter.reset_index() #Reset index of the dataframe to access both sum number and its frequency\n",
    "        win_filter = win_filter[win_filter['index'] == 1] #Filter the datframe to get frequency of 1 (win)\n",
    "        win_filter = win_filter.reset_index(drop = True) #Reset the index so that index of filter value is 0\n",
    "        win = win_filter['count'].values[0]\n",
    "    except:\n",
    "        win = 0 \n",
    "    \n",
    "    new_line['win'] = win #Add another column and store the win value\n",
    "    \n",
    "    #Repeat the process for Update Win, Loss & Update Loss\n",
    "    try:\n",
    "        df_upwin = temp[temp['upwin'] == 1]\n",
    "        df_upwin[\"count\"] = df_upwin.sum(axis=1)\n",
    "        upwin_count = df_upwin[\"count\"].value_counts()\n",
    "        upwin_filter = upwin_count.to_frame()\n",
    "        upwin_filter = upwin_filter.reset_index()\n",
    "        upwin_filter = upwin_filter[upwin_filter['index'] == 1]\n",
    "        upwin_filter = upwin_filter.reset_index(drop = True)\n",
    "        upwin = upwin_filter['count'].values[0]\n",
    "    except:\n",
    "        upwin = 0\n",
    "        \n",
    "    new_line['upwin'] = upwin\n",
    "    \n",
    "    try:\n",
    "        df_loss = temp[temp['Loss'] == 1]\n",
    "        df_loss[\"count\"] = df_loss.sum(axis=1)\n",
    "        loss_count = df_loss[\"count\"].value_counts()\n",
    "        loss_filter = loss_count.to_frame()\n",
    "        loss_filter = loss_filter.reset_index()\n",
    "        loss_filter = loss_filter[loss_filter['index'] == 1]\n",
    "        loss_filter = loss_filter.reset_index(drop = True)\n",
    "        loss = loss_filter['count'].values[0]\n",
    "    except:\n",
    "        loss = 0\n",
    "    \n",
    "    new_line['Loss'] = loss\n",
    "    \n",
    "    try:\n",
    "        df_uploss = temp[temp['update loss'] == 1]\n",
    "        df_uploss[\"count\"] = df_uploss.sum(axis=1)\n",
    "        uploss_count = df_uploss[\"count\"].value_counts()\n",
    "        uploss_filter = uploss_count.to_frame()\n",
    "        uploss_filter = uploss_filter.reset_index()\n",
    "        uploss_filter = uploss_filter[uploss_filter['index'] == 1]\n",
    "        uploss_filter = uploss_filter.reset_index(drop = True)\n",
    "        uploss = uploss_filter['count'].values[0]\n",
    "    except:\n",
    "        uploss = 0\n",
    "        \n",
    "    new_line['update loss'] = uploss\n",
    "    \n",
    "    result = result.append(new_line) #Add the new line in the empty dataframe created in line 49\n",
    "    indices.clear() #Empty the list for next iteration\n",
    "    col_name.clear() #Empty the list for next iteration\n",
    "    return result\n",
    "\n",
    "result = Parallel(n_jobs = 2) (delayed(method2)(j) for j in tqdm(switch)) #Multi Processing\n",
    "result = pd.concat(result) #Concat all DataFrames\n",
    "\n",
    "result['total'] = result['win'] + result['upwin'] + result['Loss'] + result['update loss'] #Get the total number of events\n",
    "result_filter = result[result['total'] >= min_event] #Filter the iterations which has less than threshold events\n",
    "\n",
    "#Assign weight to each event 140 to 143\n",
    "result_filter['winweight'] = result_filter['win'] * 2\n",
    "result_filter['upwinweight'] = result_filter['upwin'] * 1\n",
    "result_filter['lossweight'] = result_filter['Loss'] * 2.25\n",
    "result_filter['uplossweight'] = result_filter['update loss'] * 1.5\n",
    "\n",
    "#Calculate the Win/Loss Ratio 146 to 149\n",
    "result_filter['Win/Loss Ratio'] = (result_filter['winweight'] + result_filter['upwinweight']) / (result_filter['lossweight'] + result_filter['uplossweight'])\n",
    "result_filter.loc[(result_filter['lossweight'] == 0) & (result_filter['uplossweight'] == 0) , 'Win/Loss Ratio'] = 0\n",
    "\n",
    "result_filter = result_filter.drop(columns = ['total', 'winweight', 'upwinweight', 'lossweight', 'uplossweight'])\n",
    "#Drop Unneccessary columns\n",
    "\n",
    "result_sort = result_filter.sort_values(by = ['Win/Loss Ratio'], ascending=False) #Sort the data according Win/Loss Ratio\n",
    "method2 = result_sort.head() #Pick the top 5 iterations\n",
    "method2.to_csv('static_method2.csv', index = False) #Save the result in CSV\n",
    "method2 #Display the result in Ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input for Static Method - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Input give the value low, high and step (IN THAT ORDER ONLY)\n",
    "lower_bound_sma20 = -5,-3,2\n",
    "upper_bound_sma20 = -2,-1,1\n",
    "momentum_threshold = -50,50,25\n",
    "up_from_day = 5,10,4\n",
    "up_from_open = 10,14,2\n",
    "lower_bound_rsi = 50,70,15\n",
    "upper_bound_rsi = 60,80,15\n",
    "average_volume_ratio = 0.5,2.5,1.5\n",
    "market_cap_threshold = 500,5000,2000\n",
    "\n",
    "sma20_isgreaterthan_sma50 = 'OFF'\n",
    "sma20percent = 'OFF'\n",
    "momentum = 'ON'\n",
    "percent_change = 'OFF'\n",
    "percent_over_open = 'ON'\n",
    "rsi = 'ON'\n",
    "volume_ratio = 'OFF'\n",
    "mktcap = 'ON'\n",
    "macd = 'OFF'\n",
    "\n",
    "min_event = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Method - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch = [sma20_isgreaterthan_sma50, sma20percent, momentum, percent_change, percent_over_open, rsi, volume_ratio, \\\n",
    "          mktcap, macd] #Get all the swith (on off in a list)\n",
    "\n",
    "off_index = [i for i, x in enumerate(switch) if x == \"OFF\"] #Get the indices of OFF in a list\n",
    "off_column = off_index.copy() #Get the copy of above list. This will be used later\n",
    "\n",
    "#If the indices contains 0 or 8. Remove it. Since 'sma20 > sma50 check' and 'MACD pass/fail check' doesnt have value\n",
    "if 0 in off_index:\n",
    "    off_index.remove(0)    \n",
    "if 8 in off_index:\n",
    "    off_index.remove(8)\n",
    "\n",
    "del_col = [x+1 if x >= 6 else x for x in off_index] #Since rsi lower and upper bound are sharing a switch add 1 to variable coming after\n",
    "\n",
    "#Since 2 variables are sharing switch. Add another index if the other exist. Aligns variables indices with switch's (OFF only)\n",
    "for l in del_col:\n",
    "    if (l == 1):\n",
    "        del_col.append(0)\n",
    "    if (l == 5):\n",
    "        del_col.append(6)\n",
    "\n",
    "del_col.sort() #Sort the indices of off (THIS IS IMPORTANT)\n",
    "\n",
    "threshold_list = [lower_bound_sma20, upper_bound_sma20, momentum_threshold, up_from_day, up_from_open, lower_bound_rsi, \\\n",
    "                 upper_bound_rsi, average_volume_ratio, market_cap_threshold] #Get the low high step of variables in a list\n",
    "\n",
    "#Remove variables whose switch is off to reduce no of iterations\n",
    "for ele in sorted(del_col, reverse = True): \n",
    "    del threshold_list[ele]\n",
    "\n",
    "#Expand low, high with step of all variables. Eg: low 500 high 5000 step 2000 will give 500, 2500, 4500.\n",
    "iteration = []\n",
    "for s in threshold_list:\n",
    "    lis = list(s)\n",
    "    start = [lis[0]]\n",
    "    low = lis[0]\n",
    "    while low <= s[1]:\n",
    "        low += s[2]\n",
    "        start.append(low)\n",
    "    start.pop()\n",
    "    iteration.append(start)\n",
    "\n",
    "iterate = list(itertools.product(*iteration)) #Create all possible iterations\n",
    "\n",
    "#Since 'sma20 > sma50 check' and 'MACD pass/fail check' doesnt have variables create its 0, 1 columns\n",
    "data.loc[(data['20SMA'] > data['50SMA'] ) , 'sma20 > sma50'] = 0\n",
    "data['sma20 > sma50'] = data['sma20 > sma50'].fillna(1)\n",
    "data.loc[(data['Macd'] == 'Pass') , 'MACD'] = 0\n",
    "data['MACD'] = data['MACD'].fillna(1)\n",
    "\n",
    "data['mrkt cap'] = data['mrkt cap'].fillna(0) #Fill Blank space in market cap with 0\n",
    "data['Volume Ratio'] = data['Volume Ratio'].fillna(0) #Fill Blank space in volume ratio with 0\n",
    "\n",
    "event = ['win', 'upwin', 'Loss', 'update loss'] #Get all the events in a list\n",
    "\n",
    "#Add 'OFF' in the specified index for all the iterations created\n",
    "scenarios = []\n",
    "for j in iterate:  \n",
    "    lis = list(j)\n",
    "    \n",
    "    for k in del_col:\n",
    "        lis.insert(k, 'OFF')\n",
    "    scenarios.append(lis)\n",
    "    \n",
    "def method1(lis): #Loop Starts\n",
    "    \n",
    "    global data\n",
    "    data = data.copy(deep = True)\n",
    "    \n",
    "    result = pd.DataFrame() #Create an empty DataFrame to store result\n",
    "    col_name = [] #Create an empty list\n",
    "    \n",
    "    #Create columns with default values. Will change when conditions are met\n",
    "    data['sma20 bound check'] = 1\n",
    "    data['momentum'] = 1\n",
    "    data['8% Daily'] = 1\n",
    "    data['2% UP'] = 1\n",
    "    data['RSI (60-72)'] = 1\n",
    "    data['Volume Ration'] = 1\n",
    "    data['market cap'] = 0\n",
    "    \n",
    "    #Change the values created in column created above based on conditions. Will ignore if it is 'OFF'\n",
    "    try:\n",
    "        data.loc[(data['20SMA %'] < lis[1]) & (data['20SMA %'] > lis[0]), 'sma20 bound check'] = 0    \n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data.loc[(data['Mom'] > lis[2]) , 'momentum'] = 0\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data.loc[(data['%Up'] > lis[3]) , '8% Daily'] = 0\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data.loc[(data['% Open'] > lis[4]) , '2% UP'] = 0\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data.loc[(data['14minRSI'] < lis[6]) & (data['14minRSI'] > lis[5]), 'RSI (60-72)'] = 0\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data.loc[(data['Volume Ratio'] > lis[7]) , 'Volume Ration'] = 0\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data.loc[(data['mrkt cap'] < lis[8]) , 'market cap'] = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df = data[['sma20 > sma50','sma20 bound check', 'momentum', '8% Daily', '2% UP', 'RSI (60-72)', 'Volume Ration', \\\n",
    "           'market cap', 'MACD', 'win', 'upwin', 'Loss', 'update loss' ]] #Selecting relevant columns\n",
    "    \n",
    "    new_line = pd.DataFrame({'Lower % bound for sma20': lis[0], 'Upper % bound for sma20': lis[1], \\\n",
    "                             'Momentum threshold': lis[2], '% up for Day': lis[3], '% up from open': lis[4], \\\n",
    "          'Lower bound for RSI': lis[5], 'Upper bound for RSI': lis[6], 'Total/Average volume ratio': lis[7], \\\n",
    "                             'Market cap threshold': lis[8]}, index=[0]) #Create new line with the combination of variable for the current iterations\n",
    "    \n",
    "    #Get the col names of 'OFF' in the list created\n",
    "    for c in off_column:\n",
    "        col = df.columns[c]\n",
    "        col_name.append(col)\n",
    "\n",
    "    temp = df.drop(columns = col_name) #Drop all the OFF columns\n",
    "    \n",
    "    col_name.clear() #Clear the list \n",
    "\n",
    "    for e in event: #Loop to get the number of all events\n",
    "        try:\n",
    "            df_event = temp[temp[e] == 1] #Filter the dataset where event is 1\n",
    "            df_event[\"count\"] = df_event.sum(axis=1) #Create a new column and sum each row\n",
    "            event_count = df_event[\"count\"].value_counts() #Get the frequency of result at store in the series\n",
    "            event_filter = event_count.to_frame() #Convert the series to Dataframe\n",
    "            event_filter = event_filter.reset_index() #Reset index of the dataframe to access both sum number and its frequency\n",
    "            event_filter = event_filter[event_filter['index'] == 1] #Filter the datframe to get frequency of 1 (event)\n",
    "            event_filter = event_filter.reset_index(drop = True) #Reset the index so that index of filter value is 0\n",
    "            no_of_events = event_filter['count'].values[0] #Get the count of event\n",
    "        except:\n",
    "            no_of_events = 0  \n",
    "\n",
    "        new_line[e] = no_of_events #Add another column and store the event value\n",
    "\n",
    "    result = result.append(new_line) #Add the new line in the empty dataframe created in line 78\n",
    "    \n",
    "    data = data.drop(['sma20 bound check', 'momentum','8% Daily', '2% UP', 'RSI (60-72)', 'Volume Ration', 'market cap'],\\\n",
    "                 axis = 1) #Delete the columns created in the start of loop.\n",
    "    return result\n",
    "\n",
    "result = Parallel(n_jobs = 2) (delayed(method1)(lis) for lis in tqdm(scenarios)) #Multi Processing\n",
    "\n",
    "result = pd.concat(result) #Concat all DataFrames\n",
    "\n",
    "result['total'] = result['win'] + result['upwin'] + result['Loss'] + result['update loss'] #Get the total number of events\n",
    "result_filter = result[result['total'] >= min_event] #Filter the iterations which has less than threshold events\n",
    "\n",
    "#Assign weight to each event\n",
    "result_filter['winweight'] = result_filter['win'] * 2\n",
    "result_filter['upwinweight'] = result_filter['upwin'] * 1\n",
    "result_filter['lossweight'] = result_filter['Loss'] * 2.25\n",
    "result_filter['uplossweight'] = result_filter['update loss'] * 1.5\n",
    "\n",
    "#Calculate the Win/Loss Ratio\n",
    "result_filter['Win/Loss Ratio'] = (result_filter['winweight'] + result_filter['upwinweight']) / (result_filter['lossweight'] + result_filter['uplossweight'])\n",
    "result_filter.loc[(result_filter['lossweight'] == 0) & (result_filter['uplossweight'] == 0), 'Win/Loss Ratio'] = 0\n",
    "\n",
    "result_filter = result_filter.drop(columns = ['total', 'winweight', 'upwinweight', 'lossweight', 'uplossweight'])\n",
    "#Drop Unneccessary columns\n",
    "\n",
    "result_sort = result_filter.sort_values(by = ['Win/Loss Ratio'], ascending=False) #Sort the data according Win/Loss Ratio\n",
    "method1 = result_sort.head() #Pick the top 5 iterations\n",
    "method1.to_csv('static_method1.csv', index = False) #Save the result in CSV\n",
    "method1 #Display the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input Dynamic Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Input give the value low, high and step (IN THAT ORDER ONLY)\n",
    "lower_bound_sma20 = -5,-3,2\n",
    "upper_bound_sma20 = -2,-1,1\n",
    "momentum_threshold = -50,50,25\n",
    "up_from_day = 5,10,4\n",
    "up_from_open = 10,14,2\n",
    "lower_bound_rsi = 50,70,15\n",
    "upper_bound_rsi = 60,80,15\n",
    "average_volume_ratio = 0.5,2.5,1.5\n",
    "market_cap_threshold = 500,5000,2000\n",
    "fit_equation = 2.4,2.7,0.3 #New Line\n",
    "\n",
    "sma20_isgreaterthan_sma50 = 'ON', 'OFF'\n",
    "sma20percent = 'ON', 'OFF'\n",
    "momentum = 'ON', 'OFF'\n",
    "percent_change = 'ON', 'OFF'\n",
    "percent_over_open = 'ON', 'OFF'\n",
    "rsi = 'ON',\n",
    "volume_ratio = 'ON', 'OFF'\n",
    "mktcap = 'ON',\n",
    "macd = 'ON', 'OFF'\n",
    "fit_eq = 'ON', 'OFF' #New Line\n",
    "\n",
    "min_event = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mrkt cap'] = data['mrkt cap'].fillna(0) #Fill Blank space in market cap with 0 \n",
    "data['Volume Ratio'] = data['Volume Ratio'].fillna(0) #Fill Blank space in volume ratio with 0\n",
    "data['Fit EQ'] = data['Fit EQ'].fillna(0) #Fill Blank space in Fit EQ with 0\n",
    "\n",
    "switch = list(itertools.product(sma20_isgreaterthan_sma50, sma20percent, momentum, percent_change, percent_over_open, rsi,\\\n",
    "                       volume_ratio, mktcap, fit_eq, macd)) #Get all the permutation of 'ON' and 'OFF' FITEQ ADDED\n",
    "\n",
    "event = ['win', 'upwin', 'Loss', 'update loss'] #Get all the events in a list\n",
    "\n",
    "def filter(f): #Iteration\n",
    "    global data\n",
    "    data = data.copy(deep = True)\n",
    "    \n",
    "    result = pd.DataFrame() #Create an empty DataFrame to store result\n",
    "    col_name = [] #Create an empty list\n",
    "    \n",
    "    first_lis = list(f) #Store the element in a variable\n",
    "\n",
    "    #Assign default value to column will change if the condition is met\n",
    "    data['sma20 > sma50'] = 1 \n",
    "    data['MACD'] = 1\n",
    "    \n",
    "    #Change the values created in column created above based on conditions. Will ignore if it is 'OFF'\n",
    "    try:\n",
    "        data.loc[(data['20SMA'] > data['50SMA'] ) , 'sma20 > sma50'] = 0\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data.loc[(data['Macd'] == 'Pass') , 'MACD'] = 0\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    off_index = [i for i, x in enumerate(first_lis) if x == \"OFF\"] #Get the indices of OFF in a list\n",
    "    off_column = off_index.copy() #Get the copy of above list. This will be used later\n",
    "    #If the indices contains 0 or 9 . Remove it. Since 'sma20 > sma50 check' and 'MACD pass/fail check' doesnt have value\n",
    "    if 0 in off_index:\n",
    "        off_index.remove(0)    \n",
    "    if 9 in off_index:\n",
    "        off_index.remove(9)\n",
    "\n",
    "    del_col = [x+1 if x >= 6 else x for x in off_index] #Since rsi lower and upper bound are sharing a switch add 1 to variable coming after\n",
    "\n",
    "    #Since 2 variables are sharing switch. Add another index if the other exist aligns variables indices with switch's (OFF only)\n",
    "    for l in del_col:\n",
    "        if (l == 1):\n",
    "            del_col.append(0)\n",
    "        if (l == 5):\n",
    "            del_col.append(6)\n",
    "\n",
    "    del_col.sort() #Sort the indices of off (THIS IS IMPORTANT)\n",
    "\n",
    "    threshold_list = [lower_bound_sma20, upper_bound_sma20, momentum_threshold, up_from_day, up_from_open, lower_bound_rsi, \\\n",
    "                 upper_bound_rsi, average_volume_ratio, market_cap_threshold, fit_equation] #Get the low high step of variables in a list FITEQ ADDED\n",
    "\n",
    "    #Remove variables whose switch is off to reduce no of iterations\n",
    "    for ele in sorted(del_col, reverse = True): \n",
    "        del threshold_list[ele]\n",
    "\n",
    "    #Expand low, high with step of all variables. Eg: low 500 high 5000 step 2000 will give 500, 2500, 4500\n",
    "    iteration = []\n",
    "    for s in threshold_list:\n",
    "        lis = list(s)\n",
    "        start = [lis[0]]\n",
    "        low = lis[0]\n",
    "        while low <= s[1]:\n",
    "            low += s[2]\n",
    "            start.append(low)\n",
    "        start.pop()\n",
    "        iteration.append(start)\n",
    "\n",
    "    iterate = list(itertools.product(*iteration)) #Create all possible iterations\n",
    "\n",
    "    #Add 'OFF' in the specified index for all the iterations created in line 66 line 86 to 92\n",
    "    scenarios = []\n",
    "    for j in iterate:  \n",
    "        lis = list(j)\n",
    "        for k in del_col:\n",
    "            lis.insert(k, 'OFF')\n",
    "        scenarios.append(lis)\n",
    "\n",
    "    for lis in scenarios: #Variable Loop\n",
    "        #Create columns with default values. Will change when conditions are met\n",
    "        data['sma20 bound check'] = 1\n",
    "        data['momentum'] = 1\n",
    "        data['8% Daily'] = 1\n",
    "        data['2% UP'] = 1\n",
    "        data['RSI (60-72)'] = 1\n",
    "        data['Volume Ration'] = 1\n",
    "        data['market cap'] = 0\n",
    "        data['FitEQ'] = 0 #New Line Added\n",
    "\n",
    "        #Change the values created in column created above based on conditions. Will ignore if it is 'OFF'\n",
    "        try:\n",
    "            data.loc[(data['20SMA %'] < lis[1]) & (data['20SMA %'] > lis[0]), 'sma20 bound check'] = 0    \n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data.loc[(data['Mom'] > lis[2]) , 'momentum'] = 0\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data.loc[(data['%Up'] > lis[3]) , '8% Daily'] = 0\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data.loc[(data['% Open'] > lis[4]) , '2% UP'] = 0\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data.loc[(data['14minRSI'] < lis[6]) & (data['14minRSI'] > lis[5]), 'RSI (60-72)'] = 0\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data.loc[(data['Volume Ratio'] < lis[7]) , 'Volume Ration'] = 0\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data.loc[(data['mrkt cap'] < lis[8]) , 'market cap'] = 1\n",
    "        except:\n",
    "            pass\n",
    "        try: #New Line Added\n",
    "            data.loc[(data['Fit EQ'] < lis[9]) , 'FitEQ'] = 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        df = data[['sma20 > sma50','sma20 bound check', 'momentum', '8% Daily', '2% UP', 'RSI (60-72)', 'Volume Ration', \\\n",
    "                   'market cap', 'MACD', 'FitEQ', 'win', 'upwin', 'Loss', 'update loss']] #Selecting relevant columns FITEQ ADDED\n",
    "\n",
    "        new_line = pd.DataFrame({'sma20 > sma50 check': first_lis[0], 'Lower % bound for sma20': lis[0], \\\n",
    "                'Upper % bound for sma20': lis[1], 'Momentum threshold': lis[2], '% up for Day': lis[3], \\\n",
    "                '% up from open': lis[4], 'Lower bound for RSI': lis[5], 'Upper bound for RSI': lis[6], \\\n",
    "                'Total/Average volume ratio': lis[7], 'Market cap threshold': lis[8], 'MACD': first_lis[8], \\\n",
    "              'Fit equation threshold': lis[9]}, index=[0]) #Create new line with the combination of variable for the current iterations FITEQ ADDED\n",
    "\n",
    "        #Get the col names of 'OFF' in the list created earlier\n",
    "        for c in off_column:\n",
    "            col = df.columns[c]\n",
    "            col_name.append(col)\n",
    "\n",
    "        temp = df.drop(columns = col_name) #Drop all the OFF columns\n",
    "\n",
    "        col_name.clear() #Clear the list \n",
    "\n",
    "        for e in event: #Loop to get the number of all events\n",
    "            try:\n",
    "                df_event = temp[temp[e] == 1] #Filter the dataset where event is 1\n",
    "                df_event[\"count\"] = df_event.sum(axis=1) #Create a new column and sum each row\n",
    "                event_count = df_event[\"count\"].value_counts() #Get the frequency of result at store in the series\n",
    "                event_filter = event_count.to_frame() #Convert the series to Dataframe\n",
    "                event_filter = event_filter.reset_index() #Reset index of the dataframe to access both sum number and its frequency\n",
    "                event_filter = event_filter[event_filter['index'] == 1] #Filter the datframe to get frequency of 1 (event)\n",
    "                event_filter = event_filter.reset_index(drop = True) #Reset the index so that index of filter value is 0\n",
    "                no_of_events = event_filter['count'].values[0]\n",
    "            except:\n",
    "                no_of_events = 0\n",
    "\n",
    "            new_line[e] = no_of_events #Add another column and store the event value\n",
    "\n",
    "        result = result.append(new_line) #Add the new line in the empty dataframe created earlier\n",
    "\n",
    "        data = data.drop(['sma20 bound check', 'momentum','8% Daily', '2% UP', 'RSI (60-72)', 'Volume Ration', 'market cap'],\\\n",
    "                     axis = 1) #Delete the columns created in the start of loop.\n",
    "\n",
    "    \n",
    "    return result\n",
    "            \n",
    "\n",
    "result = Parallel(n_jobs = 2) (delayed(filter)(f) for f in tqdm(switch)) #Multi Processing\n",
    "\n",
    "result = pd.concat(result) #Concat DataFrame\n",
    "\n",
    "result['total'] = result['win'] + result['upwin'] + result['Loss'] + result['update loss'] #Get the total number of events\n",
    "result_filter = result[result['total'] >= min_event] #Filter the iterations which has less than threshold events\n",
    "\n",
    "#Assign weight to each event\n",
    "result_filter['winweight'] = result_filter['win'] * 2\n",
    "result_filter['upwinweight'] = result_filter['upwin'] * 1\n",
    "result_filter['lossweight'] = result_filter['Loss'] * 2.25\n",
    "result_filter['uplossweight'] = result_filter['update loss'] * 1.5\n",
    "\n",
    "#Calculate the Win/Loss Ratio\n",
    "result_filter['Win/Loss Ratio'] = (result_filter['winweight'] + result_filter['upwinweight']) / (result_filter['lossweight'] + result_filter['uplossweight'])\n",
    "result_filter.loc[(result_filter['lossweight'] == 0) & (result_filter['uplossweight'] == 0), 'Win/Loss Ratio'] = 0   \n",
    "\n",
    "result_filter = result_filter.drop(columns = ['total', 'winweight', 'upwinweight', 'lossweight', 'uplossweight'])\n",
    "#Drop Unneccessary columns\n",
    "\n",
    "result_sort = result_filter.sort_values(by = ['Win/Loss Ratio'], ascending=False) #Sort the data according Win/Loss Ratio\n",
    "final = result_sort.drop_duplicates(keep='last') #Drop Duplicates if any\n",
    "dynamic = final.head() #Pick the top 5 iterations\n",
    "dynamic.to_csv('dynamic.csv', index = False) #Save the result in CSV\n",
    "dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
